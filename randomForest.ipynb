{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "24cd65bf",
      "metadata": {
        "id": "24cd65bf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3af33d9a",
      "metadata": {},
      "source": [
        "# Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c8269bb5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8269bb5",
        "outputId": "3375cdae-50af-4663-cf61-cef032d91b57"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
              "        1.189e-01],\n",
              "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
              "        8.902e-02],\n",
              "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
              "        8.758e-02],\n",
              "       ...,\n",
              "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
              "        7.820e-02],\n",
              "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
              "        1.240e-01],\n",
              "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
              "        7.039e-02]])"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x, y = load_breast_cancer(return_X_y=True,as_frame=False)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "92048c03",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "92048c03",
        "outputId": "646b933b-8aa5-41e2-fbc3-b83b275baf16"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "0        17.99         10.38          122.80     1001.0          0.11840   \n",
              "1        20.57         17.77          132.90     1326.0          0.08474   \n",
              "2        19.69         21.25          130.00     1203.0          0.10960   \n",
              "3        11.42         20.38           77.58      386.1          0.14250   \n",
              "4        20.29         14.34          135.10     1297.0          0.10030   \n",
              "\n",
              "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "0           0.27760          0.3001              0.14710         0.2419   \n",
              "1           0.07864          0.0869              0.07017         0.1812   \n",
              "2           0.15990          0.1974              0.12790         0.2069   \n",
              "3           0.28390          0.2414              0.10520         0.2597   \n",
              "4           0.13280          0.1980              0.10430         0.1809   \n",
              "\n",
              "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
              "0                 0.07871  ...         25.38          17.33           184.60   \n",
              "1                 0.05667  ...         24.99          23.41           158.80   \n",
              "2                 0.05999  ...         23.57          25.53           152.50   \n",
              "3                 0.09744  ...         14.91          26.50            98.87   \n",
              "4                 0.05883  ...         22.54          16.67           152.20   \n",
              "\n",
              "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
              "0      2019.0            0.1622             0.6656           0.7119   \n",
              "1      1956.0            0.1238             0.1866           0.2416   \n",
              "2      1709.0            0.1444             0.4245           0.4504   \n",
              "3       567.7            0.2098             0.8663           0.6869   \n",
              "4      1575.0            0.1374             0.2050           0.4000   \n",
              "\n",
              "   worst concave points  worst symmetry  worst fractal dimension  \n",
              "0                0.2654          0.4601                  0.11890  \n",
              "1                0.1860          0.2750                  0.08902  \n",
              "2                0.2430          0.3613                  0.08758  \n",
              "3                0.2575          0.6638                  0.17300  \n",
              "4                0.1625          0.2364                  0.07678  \n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_df, y_df = load_breast_cancer(return_X_y=True,as_frame=True)\n",
        "x_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "609e3f1e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "609e3f1e",
        "outputId": "60d7e5cd-9c28-49ae-b6bf-d305d84e35bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
              "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "cf14cfbb",
      "metadata": {
        "id": "cf14cfbb"
      },
      "outputs": [],
      "source": [
        "x_train, x_temp, y_train, y_temp = train_test_split(x, y, train_size=0.70, random_state=42)\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.50, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e06db4c4",
      "metadata": {},
      "source": [
        "# Tree Node"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "eb63675e",
      "metadata": {
        "id": "eb63675e"
      },
      "outputs": [],
      "source": [
        "class TreeNode:\n",
        "    def __init__(self, left=None, right=None, feature=None, feature_value=None, threshold=None, gain=None, samples=None):\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.feature = feature\n",
        "        self.feature_value = feature_value\n",
        "        self.threshold = threshold\n",
        "        self.gain = gain\n",
        "        self.samples = samples\n",
        "\n",
        "    def is_leaf(self):\n",
        "        return self.feature_value is not None\n",
        "    # node becomes leaf when it has a value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "fa8df734",
      "metadata": {
        "id": "fa8df734"
      },
      "outputs": [],
      "source": [
        "class DecisionTree:\n",
        "    def __init__(self, max_depth, min_samples_split):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.root = None\n",
        "\n",
        "    def build_tree(self, x, y, depth):\n",
        "        samples, _ = x.shape # x dimensions is the samples with their features\n",
        "        classes = len(np.unique(y))\n",
        "\n",
        "        if(depth >= self.max_depth or samples < self.min_samples_split or classes == 1): # stopping conditions\n",
        "            selected_class = np.bincount(y).argmax()\n",
        "            return TreeNode(None, None, None, selected_class, None, None, samples) # return leaf node with most common class\n",
        "\n",
        "        best_feature, best_threshold, best_gain = self.select_best_split(x, y)\n",
        "        left_index, right_index = self.split_node(x, best_feature, best_threshold) # splitting the node at the best feature\n",
        "        left_subtree = self.build_tree(x[left_index, :], y[left_index], depth + 1)\n",
        "        right_subtree = self.build_tree(x[right_index, :], y[right_index], depth + 1)\n",
        "        # print(\"Depth:\", depth, \"Samples:\", samples)\n",
        "        return TreeNode(left_subtree, right_subtree, best_feature, None, best_threshold, best_gain, samples) # return new node\n",
        "\n",
        "    def calculate_Entropy(self, y):\n",
        "        counts = np.bincount(y) # counts of each class in y\n",
        "        probabilities = counts / counts.sum()\n",
        "        entropy = -np.sum([p * np.log2(p) for p in probabilities if p > 0])\n",
        "        return entropy\n",
        "\n",
        "    def split_node(self, x, feature, threshold):\n",
        "        left_index = x[:, feature] <= threshold # splitting samples at that feature and threshold\n",
        "        right_index = x[:, feature] > threshold\n",
        "\n",
        "        return left_index, right_index\n",
        "\n",
        "    def calculate_Information_Gain(self, x, y, feature, threshold):\n",
        "        original_entropy = self.calculate_Entropy(y) #H(y)\n",
        "        left_index, right_index = self.split_node(x, feature, threshold)\n",
        "        n, n_left, n_right = len(y), len(y[left_index]), len(y[right_index])\n",
        "        if n_left == 0 or n_right == 0: # no split\n",
        "            return 0\n",
        "        new_entropy = (n_left / n) * self.calculate_Entropy(y[left_index]) + (n_right / n) * self.calculate_Entropy(y[right_index]) # entropies * their weights\n",
        "        information_gain = original_entropy - new_entropy\n",
        "        return information_gain\n",
        "\n",
        "    def select_best_split(self, x, y):\n",
        "        best_information_gain = -1\n",
        "        best_feature, best_threshold = None, None\n",
        "        features = x.shape[1]\n",
        "\n",
        "        subset_size = int(np.sqrt(features))\n",
        "        feature_subset = np.random.choice(features, subset_size, replace=False)\n",
        "#  range(features) = [0,1,2,3]\n",
        "#  features subset = [3,1]\n",
        "        for feature in feature_subset:\n",
        "            values = np.sort(np.unique(x[:, feature]))\n",
        "            thresholds = (values[:-1] + values[1:]) / 2 # midpoints between values\n",
        "            for threshold in thresholds:\n",
        "                information_gain = self.calculate_Information_Gain(x, y, feature, threshold)\n",
        "                if information_gain > best_information_gain:\n",
        "                    best_information_gain = information_gain\n",
        "                    best_feature = feature\n",
        "                    best_threshold = threshold\n",
        "\n",
        "        return best_feature, best_threshold, best_information_gain\n",
        "\n",
        "    def fit(self, x, y):\n",
        "        self.features = x.shape[1]\n",
        "        self.root = self.build_tree(x, y, 0) # building the tree starting from depth 0\n",
        "\n",
        "    def traverse_tree(self, x, node): # for prediction\n",
        "        if node.is_leaf():\n",
        "            return node.feature_value\n",
        "        if x[node.feature] <= node.threshold:\n",
        "            return self.traverse_tree(x, node.left)\n",
        "        else:\n",
        "            return self.traverse_tree(x, node.right)\n",
        "\n",
        "    def predict(self, x):\n",
        "        predictions = []\n",
        "        for sample in x:\n",
        "            prediction = self.traverse_tree(sample, self.root)\n",
        "            predictions.append(prediction)\n",
        "        return predictions\n",
        "\n",
        "    def calculate_feature_importance(self):\n",
        "        feature_importance = np.zeros(self.features)\n",
        "        self.traverse_importance(self.root, feature_importance)\n",
        "        feature_importance /= feature_importance.sum() # importance normalization\n",
        "        return feature_importance\n",
        "\n",
        "    def traverse_importance(self, node, feature_importance):\n",
        "        if node.is_leaf():\n",
        "            return\n",
        "        feature_importance[node.feature] += node.gain * node.samples # calculating importance at each node\n",
        "        self.traverse_importance(node.left, feature_importance)\n",
        "        self.traverse_importance(node.right, feature_importance)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "098e489b",
      "metadata": {},
      "source": [
        "# Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "aJ7R-U4CpWZe",
      "metadata": {
        "id": "aJ7R-U4CpWZe"
      },
      "outputs": [],
      "source": [
        "class RandomForest:\n",
        "  def __init__(self, max_depth, min_samples_split, no_of_trees, max_features):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.no_of_trees = no_of_trees\n",
        "        self.max_features = max_features\n",
        "        self.trees = []\n",
        "\n",
        "  def set_no_of_trees(self, no_of_trees):\n",
        "    self.no_of_trees = no_of_trees\n",
        "  def set_max_features(self, max_features):\n",
        "    self.max_features = max_features\n",
        "  def set_max_depth(self, max_depth):\n",
        "    self.max_depth = max_depth\n",
        "  def set_min_samples_split(self, min_samples_split):\n",
        "    self.min_samples_split = min_samples_split\n",
        "\n",
        "  def build_forest(self, x_train, y_train):\n",
        "    for _ in range(self.no_of_trees):\n",
        "      tree = DecisionTree(self.max_depth, self.min_samples_split)\n",
        "      indices = np.random.choice(len(x_train), len(x_train), replace=True)\n",
        "      x_sample = x_train[indices]\n",
        "      y_sample = y_train[indices]\n",
        "      tree.fit(x_sample, y_sample)\n",
        "      self.trees.append(tree)\n",
        "\n",
        "  def predict(self, x_test):\n",
        "    predictions = [] # array of y_preds\n",
        "    for tree in self.trees:\n",
        "      predictions.append(tree.predict(x_test))\n",
        "    final_preds = []\n",
        "    for i in range(x_test.shape[0]):\n",
        "      count_1s = 0\n",
        "      count_0s = 0\n",
        "      for j in range(len(predictions)):\n",
        "        if predictions[j][i] == 1:\n",
        "          count_1s += 1\n",
        "        else:\n",
        "          count_0s += 1\n",
        "      if count_1s > count_0s:\n",
        "        final_preds.append(1)\n",
        "      else:\n",
        "        final_preds.append(0)\n",
        "    return final_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "lkkXFz1ZudnC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkkXFz1ZudnC",
        "outputId": "3617deed-ae4b-440c-8bf3-fd3c26367034"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Accuracy: 100.00%\n",
            "Test Accuracy: 96.51%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.92      0.94        26\n",
            "           1       0.97      0.98      0.98        60\n",
            "\n",
            "    accuracy                           0.97        86\n",
            "   macro avg       0.96      0.95      0.96        86\n",
            "weighted avg       0.97      0.97      0.96        86\n",
            "\n"
          ]
        }
      ],
      "source": [
        "rf = RandomForest(max_depth=10, min_samples_split=2, no_of_trees=10, max_features=np.floor(np.sqrt(x_df.shape[1])))\n",
        "rf.build_forest(x_train, y_train)\n",
        "ypred = rf.predict(x_test)\n",
        "train_accuracy = accuracy_score(y_train, rf.predict(x_train))\n",
        "test_accuracy = accuracy_score(y_test, ypred)\n",
        "print(f\"Train Accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n",
        "print(classification_report(y_test, ypred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "DpbyUiEOvN9I",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpbyUiEOvN9I",
        "outputId": "8daf469c-2e56-40cf-dec1-7df6d0cd7837"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Accuracy: 100.00%\n",
            "Test Accuracy: 96.51%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.92      0.94        26\n",
            "           1       0.97      0.98      0.98        60\n",
            "\n",
            "    accuracy                           0.97        86\n",
            "   macro avg       0.96      0.95      0.96        86\n",
            "weighted avg       0.97      0.97      0.96        86\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_accuracy = accuracy_score(y_train, rf.predict(x_train))\n",
        "test_accuracy = accuracy_score(y_test, ypred)\n",
        "print(f\"Train Accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n",
        "print(classification_report(y_test, ypred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ffeed7a",
      "metadata": {},
      "source": [
        "# Hyperparamters tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "08a6c34e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08a6c34e",
        "outputId": "d728598b-0e9d-444d-ff59-28dc91e799e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 Max Depth: 2\n",
            " Min Samples Split: 2 \n",
            " Number Of Trees: 5 \n",
            " Max Features: 5.0 \n",
            " Training Accuracy: 95.98%\n",
            " Validation Accuracy: 97.65%\n",
            "\n",
            "1 Max Depth: 2\n",
            " Min Samples Split: 2 \n",
            " Number Of Trees: 5 \n",
            " Max Features: 15.0 \n",
            " Training Accuracy: 95.73%\n",
            " Validation Accuracy: 95.29%\n",
            "\n",
            "2 Max Depth: 2\n",
            " Min Samples Split: 2 \n",
            " Number Of Trees: 10 \n",
            " Max Features: 5.0 \n",
            " Training Accuracy: 95.23%\n",
            " Validation Accuracy: 95.29%\n",
            "\n",
            "3 Max Depth: 2\n",
            " Min Samples Split: 2 \n",
            " Number Of Trees: 10 \n",
            " Max Features: 15.0 \n",
            " Training Accuracy: 95.48%\n",
            " Validation Accuracy: 95.29%\n",
            "\n",
            "4 Max Depth: 2\n",
            " Min Samples Split: 2 \n",
            " Number Of Trees: 30 \n",
            " Max Features: 5.0 \n",
            " Training Accuracy: 95.98%\n",
            " Validation Accuracy: 95.29%\n",
            "\n",
            "5 Max Depth: 2\n",
            " Min Samples Split: 2 \n",
            " Number Of Trees: 30 \n",
            " Max Features: 15.0 \n",
            " Training Accuracy: 95.73%\n",
            " Validation Accuracy: 96.47%\n",
            "\n",
            "6 Max Depth: 2\n",
            " Min Samples Split: 2 \n",
            " Number Of Trees: 50 \n",
            " Max Features: 5.0 \n",
            " Training Accuracy: 96.23%\n",
            " Validation Accuracy: 96.47%\n",
            "\n",
            "7 Max Depth: 2\n",
            " Min Samples Split: 2 \n",
            " Number Of Trees: 50 \n",
            " Max Features: 15.0 \n",
            " Training Accuracy: 95.98%\n",
            " Validation Accuracy: 96.47%\n",
            "\n",
            "8 Max Depth: 2\n",
            " Min Samples Split: 5 \n",
            " Number Of Trees: 5 \n",
            " Max Features: 5.0 \n",
            " Training Accuracy: 93.22%\n",
            " Validation Accuracy: 95.29%\n",
            "\n",
            "9 Max Depth: 2\n",
            " Min Samples Split: 5 \n",
            " Number Of Trees: 5 \n",
            " Max Features: 15.0 \n",
            " Training Accuracy: 94.72%\n",
            " Validation Accuracy: 95.29%\n",
            "\n",
            "10 Max Depth: 2\n",
            " Min Samples Split: 5 \n",
            " Number Of Trees: 10 \n",
            " Max Features: 5.0 \n",
            " Training Accuracy: 94.97%\n",
            " Validation Accuracy: 94.12%\n",
            "\n",
            "11 Max Depth: 2\n",
            " Min Samples Split: 5 \n",
            " Number Of Trees: 10 \n",
            " Max Features: 15.0 \n",
            " Training Accuracy: 94.97%\n",
            " Validation Accuracy: 92.94%\n",
            "\n",
            "12 Max Depth: 2\n",
            " Min Samples Split: 5 \n",
            " Number Of Trees: 30 \n",
            " Max Features: 5.0 \n",
            " Training Accuracy: 95.23%\n",
            " Validation Accuracy: 94.12%\n",
            "\n",
            "13 Max Depth: 2\n",
            " Min Samples Split: 5 \n",
            " Number Of Trees: 30 \n",
            " Max Features: 15.0 \n",
            " Training Accuracy: 95.73%\n",
            " Validation Accuracy: 94.12%\n",
            "\n",
            "14 Max Depth: 2\n",
            " Min Samples Split: 5 \n",
            " Number Of Trees: 50 \n",
            " Max Features: 5.0 \n",
            " Training Accuracy: 97.24%\n",
            " Validation Accuracy: 96.47%\n",
            "\n",
            "15 Max Depth: 2\n",
            " Min Samples Split: 5 \n",
            " Number Of Trees: 50 \n",
            " Max Features: 15.0 \n",
            " Training Accuracy: 96.48%\n",
            " Validation Accuracy: 96.47%\n",
            "\n",
            "16 Max Depth: 2\n",
            " Min Samples Split: 10 \n",
            " Number Of Trees: 5 \n",
            " Max Features: 5.0 \n",
            " Training Accuracy: 93.47%\n",
            " Validation Accuracy: 94.12%\n",
            "\n",
            "17 Max Depth: 2\n",
            " Min Samples Split: 10 \n",
            " Number Of Trees: 5 \n",
            " Max Features: 15.0 \n",
            " Training Accuracy: 91.96%\n",
            " Validation Accuracy: 90.59%\n",
            "\n",
            "18 Max Depth: 2\n",
            " Min Samples Split: 10 \n",
            " Number Of Trees: 10 \n",
            " Max Features: 5.0 \n",
            " Training Accuracy: 95.48%\n",
            " Validation Accuracy: 94.12%\n",
            "\n",
            "19 Max Depth: 2\n",
            " Min Samples Split: 10 \n",
            " Number Of Trees: 10 \n",
            " Max Features: 15.0 \n",
            " Training Accuracy: 94.97%\n",
            " Validation Accuracy: 95.29%\n",
            "\n",
            "20 Max Depth: 2\n",
            " Min Samples Split: 10 \n",
            " Number Of Trees: 30 \n",
            " Max Features: 5.0 \n",
            " Training Accuracy: 95.48%\n",
            " Validation Accuracy: 94.12%\n",
            "\n",
            "21 Max Depth: 2\n",
            " Min Samples Split: 10 \n",
            " Number Of Trees: 30 \n",
            " Max Features: 15.0 \n",
            " Training Accuracy: 95.48%\n",
            " Validation Accuracy: 92.94%\n",
            "\n",
            "22 Max Depth: 2\n",
            " Min Samples Split: 10 \n",
            " Number Of Trees: 50 \n",
            " Max Features: 5.0 \n",
            " Training Accuracy: 95.23%\n",
            " Validation Accuracy: 96.47%\n",
            "\n",
            "23 Max Depth: 2\n",
            " Min Samples Split: 10 \n",
            " Number Of Trees: 50 \n",
            " Max Features: 15.0 \n",
            " Training Accuracy: 95.98%\n",
            " Validation Accuracy: 96.47%\n",
            "\n",
            "24 Max Depth: 4\n",
            " Min Samples Split: 2 \n",
            " Number Of Trees: 5 \n",
            " Max Features: 5.0 \n",
            " Training Accuracy: 98.24%\n",
            " Validation Accuracy: 96.47%\n",
            "\n",
            "25 Max Depth: 4\n",
            " Min Samples Split: 2 \n",
            " Number Of Trees: 5 \n",
            " Max Features: 15.0 \n",
            " Training Accuracy: 96.98%\n",
            " Validation Accuracy: 96.47%\n",
            "\n",
            "26 Max Depth: 4\n",
            " Min Samples Split: 2 \n",
            " Number Of Trees: 10 \n",
            " Max Features: 5.0 \n",
            " Training Accuracy: 98.49%\n",
            " Validation Accuracy: 97.65%\n",
            "\n",
            "27 Max Depth: 4\n",
            " Min Samples Split: 2 \n",
            " Number Of Trees: 10 \n",
            " Max Features: 15.0 \n",
            " Training Accuracy: 98.74%\n",
            " Validation Accuracy: 98.82%\n",
            "\n",
            "28 Max Depth: 4\n",
            " Min Samples Split: 2 \n",
            " Number Of Trees: 30 \n",
            " Max Features: 5.0 \n",
            " Training Accuracy: 98.74%\n",
            " Validation Accuracy: 96.47%\n",
            "\n",
            "29 Max Depth: 4\n",
            " Min Samples Split: 2 \n",
            " Number Of Trees: 30 \n",
            " Max Features: 15.0 \n",
            " Training Accuracy: 98.99%\n",
            " Validation Accuracy: 96.47%\n",
            "\n",
            "30 Max Depth: 4\n",
            " Min Samples Split: 2 \n",
            " Number Of Trees: 50 \n",
            " Max Features: 5.0 \n",
            " Training Accuracy: 98.99%\n",
            " Validation Accuracy: 96.47%\n",
            "\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[11], line 34\u001b[0m\n\u001b[0;32m     32\u001b[0m                 best_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m val_accuracy\n\u001b[0;32m     33\u001b[0m                 best_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m train_accuracy\n\u001b[1;32m---> 34\u001b[0m \u001b[43mtuningHyperparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Parameters Found:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, best_params)\n",
            "Cell \u001b[1;32mIn[11], line 21\u001b[0m, in \u001b[0;36mtuningHyperparameters\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m max_features \u001b[38;5;129;01min\u001b[39;00m max_features_arr:\n\u001b[0;32m     20\u001b[0m   rf \u001b[38;5;241m=\u001b[39m RandomForest(max_depth, min_samples_split, no_of_trees, max_features)\n\u001b[1;32m---> 21\u001b[0m   \u001b[43mrf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_forest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m   ypred \u001b[38;5;241m=\u001b[39m rf\u001b[38;5;241m.\u001b[39mpredict(x_val)\n\u001b[0;32m     23\u001b[0m   val_accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_val, ypred)\n",
            "Cell \u001b[1;32mIn[8], line 24\u001b[0m, in \u001b[0;36mRandomForest.build_forest\u001b[1;34m(self, x_train, y_train)\u001b[0m\n\u001b[0;32m     22\u001b[0m x_sample \u001b[38;5;241m=\u001b[39m x_train[indices]\n\u001b[0;32m     23\u001b[0m y_sample \u001b[38;5;241m=\u001b[39m y_train[indices]\n\u001b[1;32m---> 24\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_sample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrees\u001b[38;5;241m.\u001b[39mappend(tree)\n",
            "Cell \u001b[1;32mIn[7], line 67\u001b[0m, in \u001b[0;36mDecisionTree.fit\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y):\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 67\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[7], line 17\u001b[0m, in \u001b[0;36mDecisionTree.build_tree\u001b[1;34m(self, x, y, depth)\u001b[0m\n\u001b[0;32m     15\u001b[0m best_feature, best_threshold, best_gain \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselect_best_split(x, y)\n\u001b[0;32m     16\u001b[0m left_index, right_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_node(x, best_feature, best_threshold) \u001b[38;5;66;03m# splitting the node at the best feature\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m left_subtree \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m right_subtree \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_tree(x[right_index, :], y[right_index], depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# print(\"Depth:\", depth, \"Samples:\", samples)\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[7], line 17\u001b[0m, in \u001b[0;36mDecisionTree.build_tree\u001b[1;34m(self, x, y, depth)\u001b[0m\n\u001b[0;32m     15\u001b[0m best_feature, best_threshold, best_gain \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselect_best_split(x, y)\n\u001b[0;32m     16\u001b[0m left_index, right_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_node(x, best_feature, best_threshold) \u001b[38;5;66;03m# splitting the node at the best feature\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m left_subtree \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m right_subtree \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_tree(x[right_index, :], y[right_index], depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# print(\"Depth:\", depth, \"Samples:\", samples)\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[7], line 15\u001b[0m, in \u001b[0;36mDecisionTree.build_tree\u001b[1;34m(self, x, y, depth)\u001b[0m\n\u001b[0;32m     12\u001b[0m     selected_class \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbincount(y)\u001b[38;5;241m.\u001b[39margmax()\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m TreeNode(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, selected_class, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, samples) \u001b[38;5;66;03m# return leaf node with most common class\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m best_feature, best_threshold, best_gain \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_best_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m left_index, right_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_node(x, best_feature, best_threshold) \u001b[38;5;66;03m# splitting the node at the best feature\u001b[39;00m\n\u001b[0;32m     17\u001b[0m left_subtree \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_tree(x[left_index, :], y[left_index], depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
            "Cell \u001b[1;32mIn[7], line 57\u001b[0m, in \u001b[0;36mDecisionTree.select_best_split\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     55\u001b[0m thresholds \u001b[38;5;241m=\u001b[39m (values[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m values[\u001b[38;5;241m1\u001b[39m:]) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;66;03m# midpoints between values\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m threshold \u001b[38;5;129;01min\u001b[39;00m thresholds:\n\u001b[1;32m---> 57\u001b[0m     information_gain \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_Information_Gain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m information_gain \u001b[38;5;241m>\u001b[39m best_information_gain:\n\u001b[0;32m     59\u001b[0m         best_information_gain \u001b[38;5;241m=\u001b[39m information_gain\n",
            "Cell \u001b[1;32mIn[7], line 35\u001b[0m, in \u001b[0;36mDecisionTree.calculate_Information_Gain\u001b[1;34m(self, x, y, feature, threshold)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_Information_Gain\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y, feature, threshold):\n\u001b[1;32m---> 35\u001b[0m     original_entropy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_Entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#H(y)\u001b[39;00m\n\u001b[0;32m     36\u001b[0m     left_index, right_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_node(x, feature, threshold)\n\u001b[0;32m     37\u001b[0m     n, n_left, n_right \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(y), \u001b[38;5;28mlen\u001b[39m(y[left_index]), \u001b[38;5;28mlen\u001b[39m(y[right_index])\n",
            "Cell \u001b[1;32mIn[7], line 25\u001b[0m, in \u001b[0;36mDecisionTree.calculate_Entropy\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m     23\u001b[0m counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbincount(y) \u001b[38;5;66;03m# counts of each class in y\u001b[39;00m\n\u001b[0;32m     24\u001b[0m probabilities \u001b[38;5;241m=\u001b[39m counts \u001b[38;5;241m/\u001b[39m counts\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m---> 25\u001b[0m entropy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39msum(\u001b[43m[\u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprobabilities\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m entropy\n",
            "Cell \u001b[1;32mIn[7], line 25\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     23\u001b[0m counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbincount(y) \u001b[38;5;66;03m# counts of each class in y\u001b[39;00m\n\u001b[0;32m     24\u001b[0m probabilities \u001b[38;5;241m=\u001b[39m counts \u001b[38;5;241m/\u001b[39m counts\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m---> 25\u001b[0m entropy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39msum([p \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog2(p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m probabilities \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m entropy\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "max_depth_arr = [2, 4, 6, 8, 10]\n",
        "min_samples_split_arr = [2, 5, 10]\n",
        "num_of_trees = [5, 10, 30, 50]\n",
        "max_features_arr = [np.floor(np.sqrt(x_df.shape[1])), np.floor(x_df.shape[1]/2)]\n",
        "best_params = {\n",
        "    \"max_depth\": None,\n",
        "    \"min_samples_split\": None,\n",
        "    \"no_of_trees\": None,\n",
        "    \"max_features\": None,\n",
        "    \"val_accuracy\": -1,   # best seen so far\n",
        "    \"train_accuracy\": -1\n",
        "}\n",
        "def tuningHyperparameters():\n",
        "    global best_params\n",
        "    index = 0\n",
        "    for max_depth in max_depth_arr:\n",
        "      for min_samples_split in min_samples_split_arr:\n",
        "        for no_of_trees in num_of_trees:\n",
        "          for max_features in max_features_arr:\n",
        "            rf = RandomForest(max_depth, min_samples_split, no_of_trees, max_features)\n",
        "            rf.build_forest(x_train, y_train)\n",
        "            ypred = rf.predict(x_val)\n",
        "            val_accuracy = accuracy_score(y_val, ypred)\n",
        "            train_accuracy = accuracy_score(y_train, rf.predict(x_train))\n",
        "            print(f\"{index} Max Depth: {max_depth}\\n Min Samples Split: {min_samples_split} \\n Number Of Trees: {no_of_trees} \\n Max Features: {max_features} \\n Training Accuracy: {train_accuracy*100:.2f}%\\n Validation Accuracy: {val_accuracy*100:.2f}%\\n\")\n",
        "            index +=1\n",
        "            if val_accuracy > best_params[\"val_accuracy\"]:\n",
        "                best_params[\"max_depth\"] = max_depth\n",
        "                best_params[\"min_samples_split\"] = min_samples_split\n",
        "                best_params[\"no_of_trees\"] = no_of_trees\n",
        "                best_params[\"max_features\"] = max_features\n",
        "                best_params[\"val_accuracy\"] = val_accuracy\n",
        "                best_params[\"train_accuracy\"] = train_accuracy\n",
        "tuningHyperparameters()\n",
        "print(\"Best Parameters Found:\\n\", best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "T-r2M-l630Bl",
      "metadata": {
        "id": "T-r2M-l630Bl"
      },
      "outputs": [],
      "source": [
        "rf.set_max_depth(best_params[\"max_depth\"])\n",
        "rf.set_min_samples_split(best_params[\"min_samples_split\"])\n",
        "rf.set_no_of_trees(best_params[\"no_of_trees\"])\n",
        "rf.set_max_features(best_params[\"max_features\"])\n",
        "rf.build_forest(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "jQw2UYs-4XXj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQw2UYs-4XXj",
        "outputId": "020b5ab2-01dc-453e-8ee1-353cd59c9dd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Accuracy: 99.25%\n",
            "Test Accuracy: 96.51%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.92      0.94        26\n",
            "           1       0.97      0.98      0.98        60\n",
            "\n",
            "    accuracy                           0.97        86\n",
            "   macro avg       0.96      0.95      0.96        86\n",
            "weighted avg       0.97      0.97      0.96        86\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_accuracy = accuracy_score(y_train, rf.predict(x_train))\n",
        "test_accuracy = accuracy_score(y_test, ypred)\n",
        "print(f\"Train Accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n",
        "print(classification_report(y_test, ypred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "36b1ce6a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "cm = confusion_matrix(y_test, ypred)\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[0,1], yticklabels=[0,1])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
